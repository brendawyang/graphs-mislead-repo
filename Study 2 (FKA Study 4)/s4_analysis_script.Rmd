---
title: "Data Analysis for Study 4"
output: 
  html_document:
    df_print: paged
    toc: true
    toc_depth: 4
    toc_float: false
---


# Study 4 Introduction

This Markdown documents the process to analyze the data for Study 4 which looked at the difference between those who received and those who did not receive a warning at the beginning of the study and the effects of this warning after a 1 day delay. 

Data was collected between August 7, 2018 and August 9, 2018 by using Amazon's Mechanical Turk for ditribution and Qualtrics as a survey platform. 

This HTML was last knitted on: `r Sys.time()`

## Set Up

### Packages and Libraries

You must run this section before you can run any other chunks.

```{r packages, echo = FALSE}
#Make sure all packages are installed

list.of.packages <- c("readr", "tidyr", "dplyr", "magrittr", "psych", "stringr", "effsize", "shiny", "readr", "lme4", "lmerTest", "kableExtra", "knitr", "ggplot2", "ggthemes", "cowplot", "pwr", "psych")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
```



```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

#turn off scientific notation
options(scipen=999)
```

```{r libraries}
#Load all libraries
library(readr)
library(tidyr)
library(dplyr)
library(magrittr)
library(effsize)
library(lme4) # for mixed effects models
library(lmerTest)
library(kableExtra)
library(knitr)#kable
library(pwr)

##Raincloud Plot Libraries
source("../R_rainclouds.R")
library(cowplot)
library(ggthemes)
library(ggplot2)

```


```{r raincloud plot}
#raincloud plot theme
raincloud_theme <- theme(
  text = element_text(size = 10),
  axis.title.x = element_text(size = 16),
  axis.title.y = element_text(size = 16, margin = margin(r = 20)),
  axis.text = element_text(size = 14),
  legend.title=element_blank(),
  legend.text=element_text(size=16),
  legend.position = "right",
  plot.title = element_text(lineheight=.8, face="bold", size = 16),
  panel.border = element_blank(),
  panel.grid.minor = element_blank(),
  panel.grid.major = element_blank(),
  panel.grid.major.y = element_line(colour = 'light gray', size=0.5, linetype='solid'),
  axis.line = element_blank(), 
  axis.ticks.y = element_blank())
```


### Data Import

```{r data import}
rating_df <- read_csv("data/clean/s4_rating_df.csv")
demographic_df <- read_csv("data/clean/s4_demographic_df.csv")
graphliteracy_df <- read_csv("data/clean/s4_graphliteracy_df.csv")
debriefing_df <- read_csv("data/clean/s4_debriefing_df.csv")
timing_df <- read_csv("data/clean/s4_timing_df.csv")
```


### Exclusions

You can exclude subjects who did not get the correct answer in the exercise by changing Exclude_Exercise_Check (line 99) to TRUE. The next time you run all the code, these participants will be excluded. 

```{r}
Exclude_Exercise_Check <- TRUE

participants_excluded <- demographic_df %>% 
  filter(check == "wrong") %>% 
  group_by(check) %>% 
  summarise(n = n())

if(Exclude_Exercise_Check == TRUE){rating_df <- rating_df %>% 
  filter(check == "right" | subject_condition == "no warning")
} else{rating_df <- rating_df}

if(Exclude_Exercise_Check == TRUE){demographic_df <- demographic_df %>% 
  filter(check == "right" | subject_condition == "no warning")
} else{demographic_df <- demographic_df}

```

For this report, **`r if(Exclude_Exercise_Check == FALSE){paste("no")} else{paste(participants_excluded$n)}`** participants are being excluded from analysis. 


```{r addtional data frames, eval = TRUE}
#Create data frames that will be used throughout

#Calculate subject means by condition for session 1
##(mean rating for truncated and mean rating for non-truncated graphs)
#NOTE: na.rm = TRUE otherwise any participant who doesn't answer 1 of the questions will have an NA for as a mean. 
subject_mean_df <- rating_df %>%
  group_by(participantid, session, subject_condition, graph_condition) %>% 
  summarise(subject_mean_rating = mean(rating, na.rm = TRUE)) %>% 
  arrange(participantid)


#Calculate subject difference rating for session 1
##(non-truncated mean rating - truncated mean rating)
subject_difference_df <- subject_mean_df %>% 
  spread(graph_condition, subject_mean_rating) %>% 
  mutate(difference =  truncated - control)

#Calculate session difference for difference rating 
##(difference for session 2 - difference for session 1)
subject_difference_session_df <- subject_difference_df %>% 
  select(-c(control, truncated)) %>% 
  spread(session, difference) %>% 
  mutate(difference =  `2` - `1`)


#Calculate subject overall graph literacy score
##(sum of graph literacy items)
subject_graphliteracy_df <- graphliteracy_df %>%
  group_by(subject_condition, participantid) %>%
  summarise(graphliteracy_sum_rating = sum(rating)) 


#Create mixed effects df
##(combination of ratings, overall graph literacy scores and some demographic questions --- education, gender and age)
models_df <- full_join(full_join(subject_graphliteracy_df, demographic_df[, c("participantid", "dem_ed", "dem_gender", "dem_age")]), rating_df)


##Create lm difference df
##(df with subject truncation effect scores (difference between truncated and control) + all demographics and graph literacy scores) 
models_difference_df <- left_join(left_join(subject_difference_df,subject_graphliteracy_df), demographic_df[, c("participantid", "dem_ed", "dem_gender", "dem_age")])



#Create trimmed timing df
##(trims anything past 2 standard deviations from each participant's individual mean for each condition)
trimmed_timing_df <- timing_df %>%
  group_by(participantid, subject_condition, graph_condition) %>%
  mutate(avg = mean(time), stdev = sd(time)) %>%
  filter(time <= 2*stdev+avg) %>%
  as.data.frame()

```

--------------

## Methods

### Participants


```{r general participant information}
n <- demographic_df %>% 
  summarise(n())
```


```{r general participant information gender}
gender <- demographic_df %>% 
  group_by(dem_gender) %>% 
  summarise(n = n())

gender
```


```{r general participant information age}
age <- demographic_df %>% 
  summarise(mean_age = mean(dem_age), sd_age = sd(dem_age), 
            median_age = median(dem_age), min_age= min(dem_age), 
            max_age = max(dem_age), range_age = max(dem_age)-min(dem_age))

age
```


`r text_spec(n, bold = T)` (`r text_spec(gender[gender$dem_gender == "female",]$n, bold = T)` women, M~age~ = `r text_spec(round(age$mean_age, 2), bold = T)`, SD~age~ = `r text_spec(round(age$sd_age, 2), bold = T)`) completed both sessions of Study 4. 

175 people completed session 1. 157 returned to complete session 2.  `r text_spec(157/175*100, bold = T)`% return rate. 

All participants reported the United States as their location and had a previous task approval rate that was equal to or exceeded 85%. 

```{r general participant information education}
education <- demographic_df %>% 
  group_by(dem_ed) %>% 
  summarise (n = n()) %>%
  mutate(percentage = n / sum(n)*100)

education
```

`r text_spec(round(sum(education[education$dem_ed >= 5,]$percentage)), bold = T)`% reported having at least a Bachelorâ€™s degree.  The samples also exhibited a range of graph literacy (see Table 1).

Achieved power for main effects
```{r}
library(pwr)

# for the smallest observed cohen's d
pwr.t.test (n = 77, d = 0.40, sig.level = 0.05, power = NULL, type = "paired")

```

```{r summary statistics for graph literacy}
#Cronbach's Alpha
library(psych)

alpha <- graphliteracy_df %>% 
  spread(graphliteracy_question, rating) %>% 
  select(-group) %>% 
  psych::alpha()

#Data Summary
subject_graphliteracy_summary <- subject_graphliteracy_df %>%
  ungroup() %>% 
  summarise(n = n(), 
            mean = mean(graphliteracy_sum_rating), 
            sd = sd(graphliteracy_sum_rating), 
            median = median(graphliteracy_sum_rating),
            min= min(graphliteracy_sum_rating), 
            max = max(graphliteracy_sum_rating), 
            range=max(graphliteracy_sum_rating)-min(graphliteracy_sum_rating)) %>% 
  mutate(alpha = round(alpha$total$std.alpha,2))

subject_graphliteracy_summary
```

### Exercise Check

79 people did not complete exercise since they were in the NO WARNING condition. 2 other people did not complete the exercise at all. 

```{r}
exercise_check <- rating_df %>% 
  filter(subject_condition == "warning") %>% 
  group_by(participantid, check) %>% 
  summarise(n()) %>% 
  group_by(check) %>% 
  summarise(n = n()) %>% 
  mutate(percentage = n / sum(n)*100)
```

`r text_spec(exercise_check[exercise_check$check == "wrong" & !is.na(exercise_check$check),]$n, bold = T)` did not get the manipulation check question right. Accuracy was `r text_spec(round(exercise_check[exercise_check$check == "right" & !is.na(exercise_check$check),]$percentage, 3), bold = T)`%

For this report, `r if(Exclude_Exercise_Check == FALSE){paste("no")} else{paste(participants_excluded$n)}` participants are being excluded from analysis. If you want to see results when participants who got the exercise wrong are excluded/included, you can go to the section called Exclusions (at the top of this file) and change **Exclude_Exercise_Check <- TRUE**


## Results

```{r subject_mean_summary by session}
subject_mean_summary <- subject_mean_df %>% 
group_by(session, subject_condition, graph_condition) %>% 
summarise(n = n(), mean = mean(subject_mean_rating), 
            sd = sd(subject_mean_rating), 
            median = median(subject_mean_rating),
            min= min(subject_mean_rating), max = max(subject_mean_rating), 
            range =max(subject_mean_rating)-min(subject_mean_rating))

subject_mean_summary
```


### The truncation effect 


We first replicated our central effect of interest: the truncation effect. 


```{r subject_mean_main}
subject_mean_main <- subject_mean_df %>% 
group_by(graph_condition) %>% 
summarise(n = n(), mean = mean(subject_mean_rating), 
            sd = sd(subject_mean_rating), 
            median = median(subject_mean_rating),
            min= min(subject_mean_rating), max = max(subject_mean_rating), 
            range =max(subject_mean_rating)-min(subject_mean_rating))

subject_mean_main

```


We found that average ratings for truncated graphs was higher than ratings for control graphs: M~control~ = `r text_spec(round(subject_mean_main$mean[subject_mean_main$graph_condition=="control"],2), bold =T)`, SD = `r text_spec(round(subject_mean_main$sd[subject_mean_main$graph_condition=="control"],2), bold =T)`; M~truncated~ = `r text_spec(round(subject_mean_main$mean[subject_mean_main$graph_condition=="truncated"],2), bold =T)`, SD = `r text_spec(round(subject_mean_main$sd[subject_mean_main$graph_condition=="truncated"],2), bold =T)`. 


```{r}
subject_mean_main_df <- subject_mean_df %>% 
  group_by(participantid, subject_condition, graph_condition) %>% 
  summarise(subject_mean_rating = mean(subject_mean_rating))
```

```{r effect size for main effect}
cohen_d <- effsize::cohen.d(subject_mean_main_df$subject_mean_rating, subject_mean_main_df$graph_condition, paired = TRUE, na.rm = TRUE)

cohen_d
```

```{r t test for main effect}
t_test <- t.test(subject_mean_rating ~ graph_condition, subject_mean_main_df, paired = TRUE)

t_test
```


This main effect was statistically significant: t(`r text_spec(round(t_test$parameter,2), bold = T)`) = `r text_spec(abs(round(t_test$statistic,2)), bold = T)`, p < `r text_spec(format(t_test$p.value,scientific = T), bold = T)`, 95% CI of difference = [0.72, 0.92],  d = `r text_spec(abs(round(cohen_d$estimate,2)), bold = T)`. 


```{r truncation effect direction}
truncation_effect_direction <- subject_difference_df %>% 
  mutate(direction = ifelse(difference > 0, "expected", "unexpected")) %>%
  group_by(session, direction) %>% 
  summarise(n= n()) %>% 
  mutate(percentage = n / sum(n)*100)

truncation_effect_direction           
```


Most participants in both sessions showed an overall truncation effect: `r text_spec(round(truncation_effect_direction[truncation_effect_direction$direction == "expected" & truncation_effect_direction$session == "1",]$percentage, 2), bold = T)`% of participants in Session 1 (`r text_spec(round(truncation_effect_direction[truncation_effect_direction$direction == "expected"& truncation_effect_direction$session == "1",]$n), bold = T)` of `r text_spec(n, bold = T)`) and `r text_spec(round(truncation_effect_direction[truncation_effect_direction$direction == "expected" & truncation_effect_direction$session == "2",]$percentage,2), bold = T)`% of participants in Session 2 (`r text_spec(round(truncation_effect_direction[truncation_effect_direction$direction == "expected"& truncation_effect_direction$session == "1",]$n), bold = T)` of `r text_spec(n, bold = T)`) .


### The truncation effect across warning conditions

Does an explanatory warning reduce the size of the truncation effect, as seen in previous studies? To interrogate an observed interaction between graph condition and warning condition , we computed models for each warning condition separately. In these two models, graph type (0 = control, 1 = truncated) served as a binary fixed factor, and the judged difference between bars was the outcome variable. Participant and item were included as random effects. 


#### No warning

```{r mixed effect model no warning}
no_warning_df <-  models_df %>% 
  filter(subject_condition == "no warning")
  
model_no_warning <- lmer(rating ~  graph_condition + (1 | participantid) +  (1 | question), no_warning_df)
summary_model_no_warning <- summary(model_no_warning)
summary_model_no_warning <- as.data.frame(summary_model_no_warning$coefficients)

summary(model_no_warning)
```

In the no warning condition, we found a significant difference between control and truncated graphs (b = `r text_spec(round(summary_model_no_warning[2,]$Estimate, 2), bold = T)`, SE = `r text_spec(round(summary_model_no_warning[2,]$"Std. Error", 2), bold = T)`, t = `r text_spec(round(summary_model_no_warning[2,]$"t value", 2), bold = T)`, p < `r text_spec(format(summary_model_no_warning[2,]$"Pr(>|t|)", scientific = T), bold = T)`) such that truncated graphs, relative to control graphs, exaggerated the judged difference between bars. In the warning condition, 


#### Warning condition

```{r mixed effect model warning}
warning_df <-  models_df %>% 
  filter(subject_condition == "warning")
  
model_warning <- lmer(rating ~  graph_condition + (1 | participantid) +  (1 | question), warning_df)
summary_model_warning <- summary(model_warning)
  summary_model_warning <- as.data.frame(summary_model_warning$coefficients)
  
summary(model_warning)
```


In the warning condition, we also found a significant difference between control and truncated graphs (b = `r text_spec(round(summary_model_warning[2,]$Estimate, 2), bold = T)`, SE = `r text_spec(round(summary_model_warning[2,]$"Std. Error", 2), bold = T)`, t = `r text_spec(round(summary_model_warning[2,]$"t value", 2), bold = T)`, p < `r text_spec(format(summary_model_warning[2,]$"Pr(>|t|)", scientific = T), bold = T)`)  such that truncated graphs, relative to control graphs, exaggerated the judged difference between bars. Nevertheless, the magnitude of the judged difference between bars is larger in the no warning condition than in the warning condition.


#### Figure 6 
```{r}

#subject_mean_df$session <- factor(subject_mean_df$session, levels = c(1, 2), labels = c("Session 1", "Session 2"))

#Flat Violin Set Up

errbar_lims <- subject_mean_df %>% 
  group_by(session, graph_condition, subject_condition) %>% 
  summarise(mean=mean(subject_mean_rating), se=sd(subject_mean_rating)/sqrt(n()), 
                        upper=mean+(2*se), lower=mean-(2*se))

subject_mean_df %<>% 
  mutate(subject_condition_2 =ifelse(subject_condition == "no warning", 1, 2))


```

```{r figure 6}


#Flat Violin Pink and Blue
ggplot(subject_mean_df, aes(x = subject_condition, y = subject_mean_rating, fill = graph_condition)) +
  geom_flat_violin(position = position_nudge(x = .15, y = 0), adjust = 1.5, trim = FALSE, alpha = .7, colour = NA)+
   facet_grid(~as.character(session))+
  
  geom_point(aes(color = graph_condition), position = position_jitter(0.1), size = 2, shape = 20,  alpha =0.7)+
  
  geom_point(data=errbar_lims, aes(x=subject_condition, y=mean, color = graph_condition), position = position_nudge(x = -0.28, y = 0))+
  
  geom_errorbar(data=errbar_lims, aes(x=subject_condition, y=mean, ymax=upper, ymin=lower, color = graph_condition),stat='identity', size = 1, width=.15, position = position_nudge(x = -0.28, y = 0))+
  
  #Color
  scale_colour_manual(values = c("#000A77", "#FF6171"))+
  scale_fill_manual(values = c("#000A77", "#FF6171"))+
  #Axis
  coord_cartesian(ylim=c(1, 7)) + 
  scale_y_continuous(breaks=seq(1, 7, 1))+
  ylab("mean rating")+
  xlab("warning condition")+
  #Theme
  raincloud_theme+
  guides(fill = guide_legend(reverse=TRUE), color = guide_legend(reverse=TRUE))+
  theme(strip.text = element_text(size=15, margin = margin(.4,0,.4,0, "cm")), strip.background = element_rect(fill="white"))+
  ggtitle("Figure 6")

#ggsave('../figures/figure6.png', plot = last_plot(), width = 8, height = 5)
#ggsave('../figures/figure6.tiff', plot = last_plot(), width = 8, height = 5, device = "tiff")
```

### Is an explanatory warning still protective 24 hours later?

To answer this, we computed linear models for Session 1 and Session. In these two models, graph type (0 = control, 1 = truncated) and warning condition (0 = no warning, 1 = warning) served as binary fixed factors, and the judged difference between bars was the outcome variable. Participant and item were modeled as random effects. 

```{r mixed effect model session 1}
session_1_df <-  models_df %>% 
  filter(session == "1")
  
model_session_1 <- lmer(rating ~  graph_condition * subject_condition + (1 | participantid) +  (1 | question), session_1_df)
summary_model_session_1 <- summary(model_session_1)
summary_model_session_1 <- as.data.frame(summary_model_session_1$coefficients)

summary_model_session_1
```


In session 1, we found a statistically significant main effect of graph type (b = `r text_spec(round(summary_model_session_1[2,]$Estimate, 2), bold = T)`, SE = `r text_spec(round(summary_model_session_1[2,]$"Std. Error", 2), bold = T)`, t = `r text_spec(round(summary_model_session_1[2,]$"t value", 2), bold = T)`, p < `r text_spec(format(summary_model_session_1[2,]$"Pr(>|t|)", scientific = T), bold = T)`) and a statistically significant interaction between graph type and warning condition (b = `r text_spec(round(summary_model_session_1[4,]$Estimate, 2), bold = T)`, SE = `r text_spec(round(summary_model_session_1[4,]$"Std. Error", 2), bold = T)`, t = `r text_spec(round(summary_model_session_1[4,]$"t value", 2), bold = T)`, p < `r text_spec(format(summary_model_session_1[4,]$"Pr(>|t|)", scientific = T), bold = T)`). 

```{r mixed effect model session 2}
session_2_df <-  models_df %>% 
  filter(session == "2")
  
model_session_2 <- lmer(rating ~  graph_condition * subject_condition + (1 | participantid) +  (1 | question), session_2_df)
summary_model_session_2 <- summary(model_session_2)
summary_model_session_2 <- as.data.frame(summary_model_session_2$coefficients)

summary_model_session_2
```

Critically, we saw a similar pattern of results in session 2: we found a statistically significant main effect of graph type (b = `r text_spec(round(summary_model_session_2[2,]$Estimate, 2), bold = T)`, SE = `r text_spec(round(summary_model_session_2[2,]$"Std. Error", 2), bold = T)`, t = `r text_spec(round(summary_model_session_2[2,]$"t value", 2), bold = T)`, p < `r text_spec(format(summary_model_session_2[2,]$"Pr(>|t|)", scientific = T), bold = T)`) and a statistically significant interaction between graph type and warning condition (b = `r text_spec(round(summary_model_session_2[4,]$Estimate, 2), bold = T)`, SE = `r text_spec(round(summary_model_session_2[4,]$"Std. Error", 2), bold = T)`, t = `r text_spec(round(summary_model_session_2[4,]$"t value", 2), bold = T)`, p < `r text_spec(format(summary_model_session_2[4,]$"Pr(>|t|)", scientific = T), bold = T)`). 

Overall, these results (summarized in Figure 6) show that an explanatory warning results in a smaller truncation effect, and that this protective effect is still present 24 hours later.

## Supplemental Information

### Methods (Supplemental Information)

#### Participants (Supplemental Information)

```{r supplemental participant informatinon language}
langauge <- demographic_df %>% 
  group_by(dem_language) %>% 
  summarise(n = n())

other_language <- demographic_df %>% 
  group_by(dem_language_2_text) %>% 
  summarise(n = n())
```


`r text_spec(langauge[2,]$n, bold = T)` participants reported English as their first language,  and `r text_spec(other_language[2,]$n, bold = T)` reported `r text_spec(other_language[2,]$dem_language_2_text, bold = T)` as their first language. 


```{r supplemental participant information education}
education <- demographic_df %>% 
  group_by(dem_ed) %>% 
  summarise (n = n()) %>%
  mutate(percentage = n / sum(n)*100)

education
   
```

`r text_spec(round(sum(education[education$dem_ed >= 5,]$percentage)), bold = T)`% of participants reported having at least a Bachelorâ€™s degree. 

```{r supplemental participant information duration}
duration_1 <- demographic_df %>% 
  summarise(mean_duration = mean(duration_min_1), 
            sd_duration = sd(duration_min_1), 
            median_duration = median(duration_min_1), 
            min_duration= min(duration_min_1), 
            max_duration = max(duration_min_1), 
            range_duration = max(duration_min_1)-min(duration_min_1))

duration_1

duration_2 <- demographic_df %>% 
  summarise(mean_duration = mean(duration_min_2), 
            sd_duration = sd(duration_min_2), 
            median_duration = median(duration_min_2), 
            min_duration= min(duration_min_2), 
            max_duration = max(duration_min_2), 
            range_duration = max(duration_min_2)-min(duration_min_2))

duration_2
```


Session 1 of the experiment took participants an average of M~duration~ = `r text_spec(round(duration_1$mean_duration, 2), bold = T)` minutes, (SD~duration~ = `r text_spec(round(duration_1$sd_duration, 2), bold = T)` minutes). 

Session 2 of the experiment took participants an average of M~duration~ = `r text_spec(round(duration_2$mean_duration, 2), bold = T)` minutes, (SD~duration~ = `r text_spec(round(duration_2$sd_duration, 2), bold = T)` minutes). 

### Results (Supplemental Information)

#### Full model (Supplemental Information)
```{r}
model_full <- lmer(rating ~ subject_condition * graph_condition * session + (1 | participantid), models_df)
summary_model_full <- summary(model_full)
summary_model_full <- as.data.frame(summary_model_full$coefficients)
```

```{r}
##Confidence Intervals
ci_model_full <- confint(model_full, "beta_", level = 0.95, method = c("boot"), nsim = 1000,  seed = 833, boot.type = c("perc"), FUN=NULL, quiet=FALSE, oldNames = TRUE)
ci_model_full <- as.data.frame(ci_model_full)


## Create and Clean Table
table_full <- merge(summary_model_full, ci_model_full, by = "row.names")
numVars <- sapply(table_full, is.numeric) 
table_full[numVars][,-c(5)] <- lapply(table_full[numVars][,-c(5)], round, digits = 2)
table_full[c(6)] <- lapply(table_full[c(6)], round, digits = 5)


table_full %<>% 
  mutate("95% CI of Estimate" =  paste("[", `2.5 %`, ",", `97.5 %`, "]", sep = "")) %>% select(Row.names, Estimate, `95% CI of Estimate`, `Std. Error`, `t value`, `Pr(>|t|)`)

table_full
```


#### Education (Supplemental Information)

Education and graph literacy 
```{r}
models_difference_df$dem_ed <- as.numeric(models_difference_df$dem_ed)

education_graphliteracy <- lm(graphliteracy_sum_rating ~ dem_ed, models_difference_df)
summary(education_graphliteracy)
```

#### Graph Literacy (Supplemental Information)

##### Main Effect

Graph literacy does not explain the size of the truncation effect
```{r graphliteracy model}
graphliteracymodel <- lmer(difference ~ graphliteracy_sum_rating + (1 | participantid), models_difference_df)
summary_graphliteracymodel <- summary(graphliteracymodel)
summary_graphliteracymodel
```


Truncation effect is mean rating for truncated graphs - mean rating for control graphs. 

```{r}
ggplot(models_difference_df, aes(x = graphliteracy_sum_rating, y = difference))+
  geom_smooth(method = lm, color = "#510D73", fill = "#510D73") +
  geom_jitter(alpha = 0.7)+
  ylab("truncation effect")+
  xlab("graph literacy score")+
  ggtitle("Figure SI4 Graph Literacy")+
  raincloud_theme+
  theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'))

ggsave('../figures/figureSI4_graphliteracy.png', plot = last_plot(), width = 6, height = 4)
```

##### Interaction with warning

Graph literacy does not significantly predict the size of the truncation effect even when you add in warning condition. 

```{r graph literacy and subject condition}
# graph literacy and subject condition 

model_literacy_warning<- lm(difference ~ graphliteracy_sum_rating * subject_condition, models_difference_df)

##Model
summary_model_literacy_warning <- summary(model_literacy_warning)

summary_model_literacy_warning
```




Truncation effect is mean rating for truncated graphs - mean rating for control graphs. 

```{r}
ggplot(models_difference_df, aes(x = graphliteracy_sum_rating, y = difference, color = subject_condition, fill = subject_condition))+
  geom_smooth(method = lm) +
  geom_jitter(alpha = 0.7)+
  ylab("truncation effect")+
  xlab("graph literacy score")+
  ggtitle("Figure SI3 Graph Literacy by Warning Condition")+
  raincloud_theme+
  theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'))+
  scale_colour_brewer(type = "div", palette = "Dark2")+
  scale_fill_brewer(type = "div", palette = "Dark2")

ggsave('../figures/figureSI3_graphliteracy_subjectcondition.png', plot = last_plot(), width = 8, height = 4)
```

##### Interaction with session

Graph literacy does not significantly predict the size of the truncation effect even when you add in warning session. 

```{r graph literacy and session}

models_difference_df$session <- as.factor(models_difference_df$session)

# graph literacy and subject condition 

model_literacy_session<- lm(difference ~ graphliteracy_sum_rating * session, models_difference_df)

##Model
summary_model_literacy_session <- summary(model_literacy_session)
summary_model_literacy_session <- as.data.frame(summary_model_literacy_session$coefficients)

summary_model_literacy_session

```




Truncation effect is mean rating for truncated graphs - mean rating for control graphs. 

```{r}
ggplot(models_difference_df, aes(x = graphliteracy_sum_rating, y = difference, color = session, fill = session))+
  geom_smooth(method = lm) +
  geom_jitter(alpha = 0.7)+
  ylab("truncation effect")+
  xlab("graph literacy score")+
  ggtitle("Figure SI3 Graph Literacy by Warning Condition")+
  raincloud_theme+
  theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'))+
  scale_colour_brewer(type = "div", palette = "Dark2")+
  scale_fill_brewer(type = "div", palette = "Dark2")

ggsave('../figures/figureSI4_graphliteracy_session.png', plot = last_plot(), width = 8, height = 4)
```


#### Age (Supplemental Information)

##### Main Effect


```{r age model}
agemodel <- lm(difference ~ dem_age, models_difference_df)
summary_agemodel <- summary(agemodel)
summary_agemodel
```


Truncation effect is mean rating for truncated graphs - mean rating for control graphs. 

```{r}
ggplot(models_difference_df, aes(x = dem_age, y = difference))+
  geom_smooth(method = lm, color = "#510D73", fill = "#510D73") +
  geom_jitter(alpha = 0.7)+
  ylab("truncation effect")+
  xlab("age")+
  ggtitle("Figure SI3 Age")+
  raincloud_theme+
  theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'))

ggsave('../figures/figureSI4_age.png', plot = last_plot(), width = 6, height = 4)
```

##### Interaction with warning


```{r age and subject condition}
# age and subject condition 
age_subjectcondition <- lm(difference ~ dem_age * subject_condition, models_difference_df)
summary(age_subjectcondition)
```


Truncation effect is mean rating for truncated graphs - mean rating for control graphs. 

```{r}
ggplot(models_difference_df, aes(x = dem_age, y = difference, color = subject_condition, fill = subject_condition))+
  geom_smooth(method = lm) +
  geom_jitter(alpha = 0.7)+
  ylab("truncation effect")+
  xlab("age")+
  ggtitle("Figure SI3 Age by Warning Condition")+
  raincloud_theme+
  theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'))+
  scale_colour_brewer(type = "div", palette = "Dark2")+
  scale_fill_brewer(type = "div", palette = "Dark2")

ggsave('../figures/figureSI4_age_subjectcondition.png', plot = last_plot(), width = 8, height = 4)
```

##### Interaction with session


```{r age and session}
models_difference_df$session <- as.factor(models_difference_df$session)

# age and subject condition 
age_session <- lm(difference ~ dem_age * session, models_difference_df)
summary(age_session)
```


Truncation effect is mean rating for truncated graphs - mean rating for control graphs. 

```{r}
ggplot(models_difference_df, aes(x = dem_age, y = difference, color = session, fill = session))+
  geom_smooth(method = lm) +
  geom_jitter(alpha = 0.7)+
  ylab("truncation effect")+
  xlab("age")+
  ggtitle("Figure SI3 Age by Warning Condition")+
  raincloud_theme+
  theme(axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'))+
  scale_colour_brewer(type = "div", palette = "Dark2")+
  scale_fill_brewer(type = "div", palette = "Dark2")

ggsave('../figures/figureSI4_age_subjectcondition.png', plot = last_plot(), width = 8, height = 4)
```


#### Item Analysis (Supplemental Information)

##### Main Effect of Warning
Here we summarise the data for each item. This is helpful to identify if the effect is driven by a few graphs or if it is seen across all graphs in the materials. 

```{r item analysis}
item_mean_df <- rating_df %>% 
  group_by(question,subject_condition) %>% 
  summarise(item_mean_rating = mean(rating)) %>% 
  arrange(question)
```

```{r}
item_mean_df %>% 
  spread(subject_condition, item_mean_rating) %>%
  mutate(diff=`no warning`- warning)
```

```{r}
item_mean_summary <- item_mean_df %>% 
  spread(subject_condition, item_mean_rating) %>%
  mutate(diff=`no warning`- warning) %>% 
  ungroup() %>% 
  summarise(n = n(), mean = mean(diff), sd = sd(diff), 
            median = median(diff), min= min(abs(diff)), 
            max = max(abs(diff)), 
            range = max(abs(diff))-min(abs(diff)))

item_mean_summary
```


```{r}
ggplot(rating_df, aes(x = subject_condition, y = rating, group = subject_condition, color = subject_condition))+
  geom_jitter(width = 0.23, alpha = 0.5)+
  stat_summary(fun.y = mean, geom = "point", color = "black") + 
  stat_summary(fun.y=mean, color="black", geom="line", aes(group = 1))+
  facet_wrap(~as.factor(question))+
  scale_colour_brewer(palette = "Dark2", direction=-1)

ggsave("../figures/figureSI4_item_analysis.png", device = "png", width = 16, height = 8, plot = last_plot(),scale = 1)
```

```{r}
item_mean_df %>% 
  spread(subject_condition, item_mean_rating) %>%
  mutate(diff=`no warning`- warning) %>% 
  filter(diff <0)
```


The effect of warning was observed for all graphs except graph 2, 12 and 40. On average, the 7-point ratings were `r text_spec(round(item_mean_summary$mean,2), bold = T)` (SD = `r text_spec(round(item_mean_summary$sd,2), bold = T)`) higher when graphs were seen in the no warning condition than when they were seen in the warning condition. The maximum average absolute difference between the no warning and the warning conditions was for graph 7 M = `r text_spec(round(item_mean_summary$max,2), bold = T)`. The minimum average absolute difference was for graph 2 where M = `r text_spec(round(item_mean_summary$min,2), bold = T)`.


##### Warning interaction with graph type 

```{r}
ggplot(rating_df, aes(x = graph_condition, y = rating, group = subject_condition, color = subject_condition))+
  geom_jitter(width = 0.23, alpha = 0.5)+
  stat_summary(fun.y = mean, geom = "point", color = "black", aes(group = subject_condition)) + 
  stat_summary(fun.y=mean, geom="line", aes(group = subject_condition))+
  facet_wrap(~as.factor(question))+
  scale_colour_brewer(palette = "Dark2", direction=-1)

ggsave("../figures/figureSI4_item_analysis_warning.png", device = "png", width = 16, height = 8, plot = last_plot(),scale = 1)
```



##### Session interaction with graph type 

```{r}
rating_df$session <- as.factor(rating_df$session)

ggplot(rating_df, aes(x = graph_condition, y = rating, group = session, color = session))+
  geom_jitter(width = 0.23, alpha = 0.5)+
  stat_summary(fun.y = mean, geom = "point", color = "black", aes(group = session)) + 
  stat_summary(fun.y=mean, geom="line", aes(group = session))+
  facet_wrap(~as.factor(question))+
  scale_colour_brewer(palette = "Dark2", direction=-1)

ggsave("../figures/figureSI4_item_analysis_session.png", device = "png", width = 16, height = 8, plot = last_plot(),scale = 1)
```


```{r eval = FALSE}
## Brenda exploratory (2019-0416)
t.test(no_warning$rating, no_warning$session, paired=TRUE)

summary(aov(rating ~ session * subject_condition * graph_condition, data = rating_df))

model1 <- lmer(rating ~ session * graph_condition + (1 | participantid), models_df)
summary(model1)

# session doesn't have an effect on the size of the truncation effect when controlling for warning
# if you run a difference ~ session t-test, there is a main effect (Mdifference= 0.68)
summary(
  lm(difference ~ subject_condition * session, subject_difference_df)
)

```


Q: Does anything change if we put all the things in?
```{r}

df <- left_join(subject_difference_df, subject_graphliteracy_df)
df <- left_join(df, demographic_df)
  
summary(
  lm(difference ~ dem_age + dem_ed + graphliteracy_sum_rating + session + subject_condition, df)
)

```


#### Timing (Supplemental Information)

```{r supplemental information timing}

Trimming <- FALSE

if(Trimming == TRUE){timing_t_df = trimmed_timing_df
} else{timing_t_df = timing_df}
```


Timing information is in seconds. 

You can choose to trim or not timing data. By default any timing that is 2 standard deviations away from the mean (for each participant for each condition) is trimmed. 

For this report, any timing that is 2 standard deviations away from the mean (for each participant for each condition) `r if(Trimming == TRUE){paste("WAS")} else{paste("WAS NOT")}` trimmed.  If you want to see results when participants who got the exercise wrong are excluded/included, you can go to the section called Exclusions (at the top of this file) and change **Trimming <- FALSE**


```{r timing interaction}
subject_timing <-  timing_t_df %>%
  filter(question != "instructions") %>% 
  group_by(participantid, graph_condition, subject_condition,session) %>%
  summarise(n = n(), subject_mean_timing = mean(time))

#Data Summary
subject_timing_interaction_summary <- subject_timing %>% 
  group_by(session, subject_condition, graph_condition) %>% 
  summarise(n = n(), mean = mean(subject_mean_timing), 
            sd = sd(subject_mean_timing), 
            median = median(subject_mean_timing), min= min(subject_mean_timing), 
            max = max(subject_mean_timing), 
            range = max(subject_mean_timing)-min(subject_mean_timing))

subject_timing_interaction_summary
```

```{r timing by session and graph condition}
#Data Summary
subject_timing_graph_summary <- subject_timing %>% 
  group_by(session, graph_condition) %>% 
  summarise(n = n(), mean = mean(subject_mean_timing), 
            sd = sd(subject_mean_timing), 
            median = median(subject_mean_timing), min= min(subject_mean_timing), 
            max = max(subject_mean_timing), 
            range = max(subject_mean_timing)-min(subject_mean_timing))

subject_timing_graph_summary
  
```


```{r timing by session and warning condition}
#Data Summary
subject_timing_warning_summary <- subject_timing %>% 
  group_by(session, subject_condition) %>% 
  summarise(n = n()/2, mean = mean(subject_mean_timing), 
            sd = sd(subject_mean_timing), 
            median = median(subject_mean_timing), min= min(subject_mean_timing), 
            max = max(subject_mean_timing), 
            range = max(subject_mean_timing)-min(subject_mean_timing))

subject_timing_warning_summary
```
